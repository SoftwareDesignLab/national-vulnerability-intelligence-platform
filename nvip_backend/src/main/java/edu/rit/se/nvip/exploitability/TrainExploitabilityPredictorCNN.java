/**
 * Copyright 2021 Rochester Institute of Technology (RIT). Developed with
 * government support under contract 70RSAT19CB0000020 awarded by the United
 * States Department of Homeland Security.
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * 
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
package edu.rit.se.nvip.exploitability;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.deeplearning4j.core.evaluation.EvaluationTools;
import org.deeplearning4j.core.storage.StatsStorage;
import org.deeplearning4j.datasets.iterator.MultipleEpochsIterator;
import org.deeplearning4j.earlystopping.EarlyStoppingConfiguration;
import org.deeplearning4j.earlystopping.EarlyStoppingModelSaver;
import org.deeplearning4j.earlystopping.EarlyStoppingResult;
import org.deeplearning4j.earlystopping.saver.InMemoryModelSaver;
import org.deeplearning4j.earlystopping.scorecalc.ClassificationScoreCalculator;
import org.deeplearning4j.earlystopping.termination.MaxEpochsTerminationCondition;
import org.deeplearning4j.earlystopping.termination.MaxTimeIterationTerminationCondition;
import org.deeplearning4j.earlystopping.trainer.EarlyStoppingGraphTrainer;
import org.deeplearning4j.earlystopping.trainer.IEarlyStoppingTrainer;
import org.deeplearning4j.eval.Evaluation;
import org.deeplearning4j.eval.ROC;
import org.deeplearning4j.eval.ROCMultiClass;
import org.deeplearning4j.models.embeddings.loader.WordVectorSerializer;
import org.deeplearning4j.models.embeddings.wordvectors.WordVectors;
import org.deeplearning4j.nn.api.Layer;
import org.deeplearning4j.nn.graph.ComputationGraph;
import org.deeplearning4j.optimize.listeners.ScoreIterationListener;
import org.deeplearning4j.ui.api.UIServer;
import org.deeplearning4j.ui.model.stats.StatsListener;
import org.deeplearning4j.ui.model.storage.InMemoryStatsStorage;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;
import edu.rit.se.nvip.cvss.utils.CompGraphDataUtils;
import edu.rit.se.nvip.cvss.utils.ModelParams;
import edu.rit.se.nvip.utils.MyProperties;
import edu.rit.se.nvip.utils.PropertyLoader;
import edu.rit.se.nvip.utils.UtilHelper;
import java.io.File;
import java.io.IOException;
import java.util.*;
import java.util.concurrent.TimeUnit;

/**
 * 
 * This class trains a CNN model for CVE severity/exploitability prediction,
 * serializes it to a file (stg like dl-exploitability.model)
 * 
 * It then uses the provided test set to calculate Precision, Recall and
 * F-Measure.
 * 
 * Some other experiments might deserialize and use the model serialized here!
 * 
 * Models: CVE Exploitability (BINARY) and CVE Severity (Multi-class)
 * 
 * 
 * @author axoeec
 *
 */
public class TrainExploitabilityPredictorCNN {
	private Logger logger = LogManager.getLogger(getClass().getSimpleName());

	/**
	 * Location (local file system) for the Google News vectors. Set this manually.
	 */
	public static String WORD_VECTORS_PATH = null;
	private static String basePath = null;
	private CompGraphDataUtils utils = new CompGraphDataUtils();

	int epochCount = 1;
	int batchSize = 32;

	// set these parameters to adjust parameter tuning process.
	int MAX_HOURS = 1;
	int MAX_EPOCHS = 3;

	public static void main(String[] args) throws Exception {
		TrainExploitabilityPredictorCNN cnnSentenceClassification = new TrainExploitabilityPredictorCNN();
		cnnSentenceClassification.trainAndSerialize(1, 32);

	}

	public void trainAndSerialize(int epochCount, int batchSize) {
		// this.epochCount = epochCount;
		// this.batchSize = batchSize;
		MyProperties proeperties = new MyProperties();
		proeperties = new PropertyLoader().loadConfigFile(proeperties);
		basePath = proeperties.getDataDir() + "/characterization/cvss";
		WORD_VECTORS_PATH = basePath + "/" + ModelParams.getWordvectorfile();
//		 WORD_VECTORS_PATH = basePath + "/CveWord2vec.gz";

		/**
		 * Train BINARY exploitability model: Use exploitability data at 2010 as
		 * training and 2011-2013 as test!
		 * 
		 */
		List<String> labels = new ArrayList<String>();

		labels.clear();
		labels.add("0");
		labels.add("1");

		this.epochCount = 3;
		trainCNNModel("exploitability", "dl-exploitability.model", "ExploitabilityBinaryData-2011-2012-2013", false, labels, false); // CVE explotability

		labels.clear();
		labels.add("LOW");
		labels.add("MEDIUM");
		labels.add("HIGH");
		labels.add("CRITICAL");
		this.epochCount = 1;
		trainCNNModel("nvd-cve-1999-2019", "dl-nvd-cve-1999-2019.model", "nvd-cve-2020_v2", true, labels, false); // generate binary model for CVE severity
	}

	/**
	 *
	 * Prepare the data directories using the provided training and test arff files.
	 * Then train a CNN model using parameter optimization
	 * "EarlyStoppingConfiguration" to decide epoch count. When the tuning is done,
	 * select best model trained, serialize it to <modelFileName>, and test it on
	 * the provided test set.
	 * 
	 * @param trainingDataFileNameWithoutExtension
	 * @param modelFileName
	 * @param testDataFileNameWithoutExtension
	 * @param multiclass                           TODO
	 * @param labels                               TODO
	 */
	private void trainCNNModel(String trainingDataFileNameWithoutExtension, String modelFileName, String testDataFileNameWithoutExtension, boolean multiclass, List<String> labels, boolean tuneTrainingEpochs) {

		// prepare training data
		String arffDataPath = basePath + "/" + trainingDataFileNameWithoutExtension + ".arff";
		utils.prepareData(basePath, arffDataPath);

		// prepare test data
		arffDataPath = basePath + "/" + testDataFileNameWithoutExtension + ".arff";
		utils.prepareData(basePath, arffDataPath);

		String trainingDataPath = basePath + "/" + trainingDataFileNameWithoutExtension;

		String modelName = basePath + "/" + modelFileName;

		String testDataPath = basePath + "/" + testDataFileNameWithoutExtension;

		logger.info("Traininig with data: " + arffDataPath + ", Trained model will be at: " + modelName);
		trainCNNModel(labels, trainingDataPath, modelName, testDataPath, multiclass, tuneTrainingEpochs);
	}

	private StatsStorage initUiStatsStorageForDl4j(ComputationGraph net) {
		// Initialize the user interface backend
		UIServer uiServer = UIServer.getInstance();

		// Configure where the network information (gradients, score vs. time etc) is to
		// be stored. Here:
		// store in memory.
		StatsStorage statsStorage = new InMemoryStatsStorage(); // Alternative: new FileStatsStorage(File), for saving and loading later

		// Attach the StatsStorage instance to the UI: this allows the contents of the
		// StatsStorage to be
		// visualized
		uiServer.attach(statsStorage);

		return statsStorage;
	}

	/**
	 * train a model and serialize it.
	 * 
	 * @param multiclass         TODO
	 * @param tuneTrainingEpochs TODO
	 * 
	 * @param dataLabels:        The labels of the data
	 * @param trainingDataPath:  The physical path of the data
	 * @param modelName:         The name of the model for serialization
	 */
	private void trainCNNModel(List<String> dataLabels, String trainingDataPath, String modelName, String testDataPath, boolean multiclass, boolean tuneTrainingEpochs) {

		// init net
		ComputationGraph net = utils.initDLCNNNetForExploitability(dataLabels, multiclass);

		logger.info("Number of parameters by layer:");
		for (Layer l : net.getLayers()) {
			logger.info("\t" + l.conf().getLayer().getLayerName() + "\t" + l.numParams());
		}

		// Load word vectors and get the DataSetIterators for training and testing
		logger.info("Loading word vectors and creating DataSetIterators");
		WordVectors wordVectors = WordVectorSerializer.loadStaticModel(new File(WORD_VECTORS_PATH));
//		DataSetIterator trainingData = utils.getDataSetIterator(dataLabels, dataPath, wordVectors, GlobalParams.getBatchsize(), GlobalParams.getTruncatedocumentstolength(),
//				GlobalParams.getRandomnumbergenerator());

		logger.info("Load training data");
		DataSetIterator trainingData = utils.getDataSetIterator(dataLabels, trainingDataPath, wordVectors, batchSize, ModelParams.getTruncatedocumentstolength(), ModelParams.getRandomnumbergenerator());

		logger.info("Associating DL4J UI...");
		StatsStorage statsStorage = initUiStatsStorageForDl4j(net);

		// output score per XX items
		// add the StatsListener to collect information from the network, as it trains
		net.setListeners(new ScoreIterationListener(ModelParams.getPrintscoreperitems()), new StatsListener(statsStorage));

		logger.info("Loading test data for parameter optimization and testing...");
		DataSetIterator testData = utils.getDataSetIterator(dataLabels, testDataPath, wordVectors, batchSize, ModelParams.getTruncatedocumentstolength(), ModelParams.getRandomnumbergenerator());

		if (tuneTrainingEpochs) {
			logger.info("Initializing EarlyStoppingConfiguration...");
			EarlyStoppingModelSaver<ComputationGraph> saver = new InMemoryModelSaver<>();

			EarlyStoppingConfiguration<ComputationGraph> esConf = new EarlyStoppingConfiguration.Builder().epochTerminationConditions(new MaxEpochsTerminationCondition(MAX_EPOCHS))
					.iterationTerminationConditions(new MaxTimeIterationTerminationCondition(MAX_HOURS, TimeUnit.HOURS))
					// .scoreCalculator(new DataSetLossCalculatorCG(testData,true))
					.scoreCalculator(new ClassificationScoreCalculator(Evaluation.Metric.F1.toNd4j(), testData)).modelSaver(saver).build();

			logger.info("Start training net...");
			IEarlyStoppingTrainer<ComputationGraph> trainer = new EarlyStoppingGraphTrainer(esConf, net, trainingData);
			EarlyStoppingResult<ComputationGraph> result = trainer.fit();

			logger.info("Getting best model");
			// Get the best model:
			net = (ComputationGraph) result.getBestModel();
		} else {

			// net.fit(trainingData); //this is one epoch!
			logger.info("Training for " + epochCount + " epochs...");
			MultipleEpochsIterator trainIter = new MultipleEpochsIterator(epochCount, trainingData); // multiple epochs?
			net.fit(trainIter);
		}
		logger.info("Training done! Saving model to " + modelName + "\tBatchSize: " + batchSize);

		try {
			net.save(new File(modelName)); // save model
		} catch (IOException e) {
			e.printStackTrace();
			logger.error(e.toString());
		}

		logger.info("Counting items in test set...");
		testData.reset();
		int count = 0;
		while (testData.hasNext()) {
			count += testData.next().numExamples();
		}
		testData.reset();

		logger.info("Evaluating test set...");
		logger.info("Now testing the trained model[" + modelName + "] on " + count + " CVEs in the test set at: " + testDataPath);
		Evaluation eval1 = net.evaluate(testData);

		try {
			String rocChartFileName = modelName + ".html";
			Evaluation eval = new Evaluation();
			if (multiclass) {
				ROCMultiClass roc = new ROCMultiClass();
				net.doEvaluation(testData, eval, roc);
				EvaluationTools.exportRocChartsToHtmlFile(roc, new File(rocChartFileName));
			} else {
				ROC roc = new ROC();
				net.doEvaluation(testData, eval, roc);
				EvaluationTools.exportRocChartsToHtmlFile(roc, new File(rocChartFileName));
			}

			logger.info("Test result: " + eval.stats());
			logger.info("Label:\\tPrecision\\tRecall\\F1");
			for (int labelIndex = 0; labelIndex < eval.getLabelsList().size(); labelIndex++) {
				logger.info(eval1.getClassLabel(labelIndex) + ":\t" + eval.precision(labelIndex) + "\t" + eval.recall(labelIndex) + "\t" + eval.f1(labelIndex));
			}
			logger.info("ROC curve at: " + rocChartFileName);

		} catch (Exception e) {
			e.printStackTrace();
		}

	}

}
