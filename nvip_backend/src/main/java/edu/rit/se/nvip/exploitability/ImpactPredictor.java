
/**
 * Copyright 2021 Rochester Institute of Technology (RIT). Developed with
 * government support under contract 70RSAT19CB0000020 awarded by the United
 * States Department of Homeland Security.
 * 
 * Permission is hereby granted, free of charge, to any person obtaining a copy
 * of this software and associated documentation files (the "Software"), to deal
 * in the Software without restriction, including without limitation the rights
 * to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
 * copies of the Software, and to permit persons to whom the Software is
 * furnished to do so, subject to the following conditions:
 * 
 * The above copyright notice and this permission notice shall be included in
 * all copies or substantial portions of the Software.
 * 
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
 * IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
 * FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
 * AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 * LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 * OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */
package edu.rit.se.nvip.exploitability;

import java.io.File;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Arrays;
import java.util.Collections;
import java.util.HashMap;
import java.util.List;
import java.util.Map;
import java.util.Random;

import org.apache.logging.log4j.LogManager;
import org.apache.logging.log4j.Logger;
import org.deeplearning4j.iterator.CnnSentenceDataSetIterator;
import org.deeplearning4j.models.embeddings.loader.WordVectorSerializer;
import org.deeplearning4j.models.embeddings.wordvectors.WordVectors;
import org.deeplearning4j.nn.graph.ComputationGraph;
import org.nd4j.linalg.api.ndarray.INDArray;
import org.nd4j.linalg.dataset.api.iterator.DataSetIterator;

import edu.rit.se.nvip.cvss.utils.CompGraphDataUtils;
import edu.rit.se.nvip.utils.MyProperties;
import edu.rit.se.nvip.utils.PropertyLoader;
import edu.rit.se.nvip.utils.UtilHelper;

/**
 * 
 * Deserialize impact predictor
 * 
 * @author axoeec
 *
 */
public class ImpactPredictor {
	private static Logger logger = LogManager.getLogger(SeverityPredictor.class);
	static String dataPath = null;
	String WORD_VECTORS_PATH = null;
	ComputationGraph cveImpactModel = null;
	DataSetIterator impactDataset = null;

	public static void main(String[] args) {

		MyProperties propertiesNvip = new MyProperties();
		propertiesNvip = new PropertyLoader().loadConfigFile(propertiesNvip);

		ImpactPredictor severityImpactPredictor = new ImpactPredictor(propertiesNvip.getDataDir());

		List<String> cve = new ArrayList<String>();
		String cveText = "Telnet allows a remote client including LD_LIBRARY_PATH  allowing an attacker to bypass the normal system libraries and gain root access";
		cve.add(cveText);
		cveText = "Webmail in Sun ONE Messaging Server 6.1 and iPlanet Messaging Server 5.2 before 5.2hf2.02 allows remote attackers to obtain unspecified  access  to e-mail via a crafted e-mail message  related to a  session hijacking  issue  a different vulnerability than CVE-2005-2022 and CVE-2006-5486.";
		cve.add(cveText);

		for (String txt : cve) {
			String[] pred = severityImpactPredictor.predictImpact(txt);
			logger.info("Predicted impact: " + Arrays.deepToString(pred));
		}

	}

	public ImpactPredictor(String dataDir) {

		dataPath = dataDir + "/characterization/cvss";
		WORD_VECTORS_PATH = dataPath + "/GoogleNews-vectors-negative300-SLIM.bin.gz";

		/**
		 * load impact model
		 */
		String impactDataPath = null;

		impactDataPath = dataPath + "/impact";
		List<String> impactLabels = new ArrayList<String>();
		for (int i = 0; i <= 10; i++)
			impactLabels.add(String.valueOf(i));
		impactLabels.remove("2");

		impactDataset = loadData(impactLabels, impactDataPath);

		try {
			cveImpactModel = ComputationGraph.load(new File(dataPath + "/dl-impact.model"), true);
		} catch (IOException e) {
			logger.error("Error loading impact ML model: " + e.toString());
		}
		logger.info("Loaded impact model!");
	}

	private DataSetIterator loadData(List<String> severityLabels, String dataPath) {
		Random rng = new Random(12345);
		WordVectors wordVectors = WordVectorSerializer.loadStaticModel(new File(WORD_VECTORS_PATH));
		CompGraphDataUtils compGraphDataUtils = new CompGraphDataUtils();
		return compGraphDataUtils.getDataSetIterator(severityLabels, dataPath, wordVectors, 8, 256, rng);
	}

	public String[] predictImpact(String cveText) {
		try {

			INDArray severityFeatures = ((CnnSentenceDataSetIterator) impactDataset).loadSingleSentence(cveText);
			INDArray predictions = cveImpactModel.outputSingle(severityFeatures);

			// logger.info("\n\nPredictions for cve:");
			Map<String, Double> map = new HashMap<String, Double>();
			for (int i = 0; i < impactDataset.getLabels().size() - 1; i++) {
				// logger.info("P(" + impactDataset.getLabels().get(i) + ") = " +
				// predictions.getDouble(i));
				map.put(impactDataset.getLabels().get(i), predictions.getDouble(i));
			}

			String key = Collections.max(map.entrySet(), Map.Entry.comparingByValue()).getKey();
			String[] prediction = new String[] { key, map.get(key) + "" };
			return prediction;
		} catch (Exception ignored) {
			// logger.error(e.toString());
		}

		return new String[] { "n/a", "0" };
	}

}
